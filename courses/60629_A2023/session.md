| [MATH80629](main.md) | [Prérequis](prerequisition.md) | [Calendrier](session.md) | [Évaluation](evaluation.md) |  [Soutien](support.md) | [Référence](refrence.md)|

___
1- <span style="font-size:1em;">Séance 1 (le 30 Août): **Introduction au cours et rappels mathématiques**</span>
- **Lecture**: 
  * [Diapos](https://www.cs.toronto.edu/~lcharlin/courses/60629/slides_intro_fr.pdf)
  * **Lecture obligatoire:**[Prologue to The Master Algorithm](http://homes.cs.washington.edu/~pedrod/Prologue.pdf)
  * **Lecture suggérée:**
    * [Chapitre 1 de ESL](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)
    * [Rappel d'algèbre linéaire](https://www.deeplearningbook.org/contents/linear_algebra.html)
    * [Rappel de probabilité](https://www.deeplearningbook.org/contents/prob.html)
    

___
2- <span style="font-size:1em;">Séance 2 (le 6 Septembre): **Les fondements de l'apprentissage automatiques**</span> 
- **Capsules**: 
  * [Diapos](https://www.cs.toronto.edu/~lcharlin/courses/60629/slides_ml-fundamentals.pdf)
  * [Learning Problem](https://youtu.be/XHjYLAooCQI) [14:40]
  * [Types of Experiences](https://youtu.be/bUrw6MWiI7E) [13:15]
  * [A first Supervised Model](https://www.youtube.com/watch?v=fu8IBbPREBg) [8:03]
  * [Model Evaluation](https://youtu.be/jB69v09vrn8) [15:26]
  * [Regularization](https://www.youtube.com/watch?v=SFzhFrWOTEI) [4:09]
  * [Model Validation](https://www.youtube.com/watch?v=WoFGyFvyoeo) [3:08]
  * [Bias / Variance tradeoff](https://www.youtube.com/watch?v=L5Hehy9s8SI) [11:50]
- **Lecture obligatoire:**:  
  * [Chapter 5 of Deep Learning](http://www.deeplearningbook.org/contents/ml.html). You can skip 5.4 (except 5.4.4) to 5.10.  
- **Matériel pour la classe:**:  
  * [Résumé](https://www.cs.toronto.edu/~lcharlin/courses/60629/slides_ml-fundamentals_summary_fr.pdf).
  * [Exercices](https://colab.research.google.com/github/lcharlin/80-629/blob/master/week2-Fundamentals/Fundamentals_questions_fr.ipynb), 
  * [Solution](https://colab.research.google.com/github/lcharlin/80-629/blob/master/week2-Fundamentals/Fundamentals_answers_fr.ipynb)
  
___
3- <span style="font-size:1em;">Séance 3 (le 13 Septembre): **Modèles d'apprentissage supervisé**</span> 
- **Capsules**: 
  * [Slides](http://www.cs.toronto.edu/~lcharlin/courses/80-629/slides_supervised.pdf)
  * [Nearest Neighbor](https://youtu.be/wrpB9mxmhJc) [19:05]
  * [Linear Classification](https://youtu.be/Kv8Ab2I_7CM) [15:26]
  * [Introduction to Probabilistic Models (for Classification)](https://youtu.be/CnJTkeJpJLY) [11:55]
  * [The Naive Bayes Model](https://youtu.be/8L2ZM20BdoA) [24:28]
  * [Naive Bayes Example](https://youtu.be/xg8wZOr6zrY) [9:26]
- **Lecture**: Sections 4.1-4.3, 4.5 of The Elements of Statistical Learning (available [online](https://web.stanford.edu/~hastie/ElemStatLearn/)), Sections 3.5 and 4.2 of Machine Learning (K. Murphy)
- **Matériel pour la classe:**:  
  * [Résumé](https://www.cs.toronto.edu/~lcharlin/courses/60629/slidesClassificationSummary_fr.pdf).
  * [Exercices](https://colab.research.google.com/github/lcharlin/80-629/blob/master/week3-Supervised/Supervised_questions_fr.ipynb), 
  * [Solution](https://colab.research.google.com/github/lcharlin/80-629/blob/master/week3-Supervised/Supervised_answers_fr.ipynb)

___
4- <span style="font-size:1em;">Séance 4 (le 20 Septembre): **Python pour la programmation scientifique et pour l'apprentissage automatique [Séance pratique]**</span> 
- **ATENTION:** 
  * Pour cette séance pratique, il est obligatoire d'avoir un ordinateur portable!
  * Je vous recommande de démarrer le tutoriel la semaine avant le cours et de le terminer pendant le cours.

- **Lecture**: 
  * [Tutorial](https://colab.research.google.com/github/lcharlin/80-629/blob/master/week4-PracticalSession/Introduction%20pratique%20a%20l'apprentissage%20automatique.ipynb)
  * [Solution](https://colab.research.google.com/github/lcharlin/80-629/blob/master/week4-PracticalSession/Introduction%20pratique%20a%20l'apprentissage%20automatique_Solutions.ipynb)

___
5- <span style="font-size:1em;">Séance 5 (le 27 Septembre): **Réseaux de neurones et apprentissage profond**</span> 

- **Capsules**: 
  * [Slides](http://www.cs.toronto.edu/~lcharlin/courses/80-629/slides_nn.pdf)
  * [From linear classification to neural networks](https://youtu.be/Bs6NA2gGz78) [19:28]
  * [Training neural networks](https://youtu.be/c47a3YxIG7k) [20:14]
  * [Learning representations](https://youtu.be/N_JU7egyGGA)  [13:40]
  * [Neural networks hyperparameters](https://youtu.be/5axp1O299qM)  [25:20]
  * [Neural networks takeaways](https://youtu.be/Nqs-C7wBVQo) [7:00]
- **Lecture obligatoire**: 6.1--6.3 et 6.5 du livre [DL](http://www.deeplearningbook.org/contents/mlp.html) (arrëtez à 6.5.4).  
- **Lecture facultatif**:  Chapitre 11 du livre [ESL](https://web.stanford.edu/~hastie/Papers/ESLII.pdf).
- **Matériel pour la classe:**:  
  * [Résumé](https://www.cs.toronto.edu/~lcharlin/courses/60629/slides_nn_summary_fr.pdf)
  * [Exercices](https://colab.research.google.com/github/lcharlin/80-629/blob/master/week5-NeuralNetworks/Neural_Networks_questions_fr.ipynb)
  * [Solution](https://colab.research.google.com/github/lcharlin/80-629/blob/master/week5-NeuralNetworks/Neural_Networks_answers_fr.ipynb)

___
6- <span style="font-size:1em;">Séance 6 (le 4 Octobre): **Réseaux de neurones récurrents et réseaux de neurones à convolutions**</span> 
- **Capsules**: 
  * [Slides](http://www.cs.toronto.edu/~lcharlin/courses/80-629/slides_rnn-cnn.pdf)
  * [Modelling Sequential Data](https://youtu.be/Ra_n9vJ89wM) [8:42]
  * [Practical Overview of RNNs](https://youtu.be/2euWyjhO0GM) [29:32]
  * [RNNs for language modelling](https://youtu.be/K-l8zCBuJbM) [15:13]
  * [Overview of CNNs](https://youtu.be/EVZOThR2q1I) [13:30]
  * [Convolutions and Pooling](https://youtu.be/L8tbxFKKoVw) [26:00]
  * [Conclusions and Practical remarks](https://youtu.be/mA71uUtkcXw) [9:17]
- **Lecture obligatoire**: Sections 10, 10.1, 10.2 (survoler 10.2.2, sauter 10.2.3) et 10.7. Sections 9, 9.1, 9.2, 9.3 (9.11 pour le plaisir). Les deux venant de [DL](http://www.deeplearningbook.org/contents/mlp.html)
- **Matériel pour la classe:**:  
  * [Résumé](https://www.cs.toronto.edu/~lcharlin/courses/60629/slides_rnn-cnn_summary_fr.pdf)
  * [Exercices_RNNs](https://colab.research.google.com/github/lcharlin/80-629/blob/master/week6-RNNs%2BCNNs/RNNs_Questions_fr.ipynb)
  * [Solution_RNNs](https://colab.research.google.com/github/lcharlin/80-629/blob/master/week6-RNNs%2BCNNs/RNNs_Answers_fr.ipynb)
  * [Exercices_CNNs](https://colab.research.google.com/github/lcharlin/80-629/blob/master/week6-RNNs%2BCNNs/CNNs_Questions_fr.ipynb)
  * [Solution_CNNs](https://colab.research.google.com/github/lcharlin/80-629/blob/master/week6-RNNs%2BCNNs/CNNs_Answers_fr.ipynb)



___
7- <span style="font-size:1em;">Séance 6 (le 11 Octobre): **Apprentissage Non supervisé**</span> 
- **Capsules**: 
  * [Slides](http://www.cs.toronto.edu/~lcharlin/courses/80-629/slides_unsupervised.pdf)
  * [Introduction to unsupervised learning](https://youtu.be/z_PcTBDHvOs) [8:17]
  * [K-means clustering](https://youtu.be/9EFWKAQ3TSs) [41:58] (there's a natural break at 22:28)
  * [GMMs for clustering](https://youtu.be/OyK4tX2hjMc) [17:52]
  * [Beyond Clustering](https://youtu.be/zVoi--FTiYk) [14:42]
- **Lecture obligatoire**: Section 14.3 (sauf 14.3.5 et 14.3.12) du livre [ESL]
- **Matériel pour la classe:**:  
  * [Résumé](https://www.cs.toronto.edu/~lcharlin/courses/60629/slidesUnsupervisedSummary_fr.pdf)
  * [Exercices](https://colab.research.google.com/github/lcharlin/80-629/blob/master/week7-Unsupervised/Unsupervised_questions_fr.ipynb)
  * [Solution](https://colab.research.google.com/github/lcharlin/80-629/blob/master/week7-Unsupervised/Unsupervised_answers_fr.ipynb)

___
8- <span style="font-size:1em;"> Semaine d'étude (le 18 Octobre): **pas de cours** </span> 

___
9- <span style="font-size:1em;"> Proposition du projet(le 25 Octobre): **Rencontre en équipe à propos du projet**</span> 

___
10- <span style="font-size:1em;">Séance 7 (le 1 Novembre): **Calcul parallèle pour données massives**</span>
- **ATENTION:** 
  * Cette séance ne sera pas donnée en pédagogie inversée.
- **Capsules**: 
  * [Slides](http://www.cs.toronto.edu/~lcharlin/courses/80-629/slides_largeScale.pdf)
  * [Introduction to Distributed Computing for ML](https://youtu.be/CtYOBS9pDvg) [19:35]
  * [MapReduce](https://youtu.be/U3FLRYH3R5Q) [17:41]
  * [Spark](https://www.youtube.com/watch?v=4gOdejqyHng) [17:37]
- **Matériel pour la classe:**:  
  * [Diapos](https://www.cs.toronto.edu/~lcharlin/courses/60629/slides_largeScale_fr.pdf)
  * [Résumé](https://www.cs.toronto.edu/~lcharlin/courses/60629/summary-midterm-fr.pdf)
___
11- <span style="font-size:1em;">Séance 8 (le 8 Novembre): **Systèmes de recommandations**</span> 
- **Lecture obligatoire**: [Présentation du cas et du dérolement de la séance](https://www.cs.toronto.edu/~lcharlin/courses/60629/cas_Decathlon-preparation.pdf) et réponse à la Question 1 à remettre la veille du cours au plus tard)
- **Matériel pour la classe:**:  
  * [Diapos](https://www.cs.toronto.edu/~lcharlin/courses/60629/cas_Decathlon-diapos.pdf)
  * Référence (facultative)[Tutoriel sur les systèmes de recommandation](https://github.com/lcharlin/80-629/blob/master/week11-RecommenderSystems/Tutoriel-FR/SRMF%20-%20Questions.ipynb)
___
12- <span style="font-size:1em;">Séance 9 (le 15 Novembre): **Prise de décision séquentielle I**</span> 
- **Capsules**: 
  * [Slides](http://www.cs.toronto.edu/~lcharlin/courses/80-629/slides_rl.pdf)
  * [Motivating RL](https://youtu.be/V2WrKWyiPoQ) [8:22]
  * [Planning with MDPs](https://youtu.be/FwQQCSL5I_Y) [12:16]
  * [MDP objective](https://youtu.be/3vX-J61A8NQ) [14:16]
  * [Algorithms for solving MDPs](https://youtu.be/HBTyOjt4QBk) [17:51]: Note: In this capsule, there is a mistake in the second equation of the policy iteration algorithm (the transition should be given a and not π(s)), the slides have been corrected (see slides 47 and 48)

- **Lecture facultatif**: Optional: [Démonstration de l'algorithme policy iteration](https://www.cs.toronto.edu/~lcharlin/courses/60629/reinforcejs/gridworld_dp.html) (de Andrej Karpathy)

___
13- <span style="font-size:1em;">Séance 10 (le 22 Novembre): **Prise de décision séquentielle II**</span> 
- **Lecture**: 
- **Capsules**: 
  * [Dapo](http://www.cs.toronto.edu/~lcharlin/courses/80-629/slides_rl2.pdf)
  * [Introduction to RL](https://www.youtube.com/watch?v=VnZ4558bXys) [13:31]
  * [A first RL algorithm](https://www.youtube.com/watch?v=EYeACgMxHVk) [17:13]
  * [RL Algorithms for Control](https://www.youtube.com/watch?v=PeGnFc5S-f4) [21:10]

- **Lectures obligatoires**: Sections 1 à 4 de cet [Article](https://www.jair.org/index.php/jair/article/download/10166/24110/), 
- **Lectures complementaires**:  Chapiters 1,3,4, et 6 de [Livre](http://incompleteideas.net/book/the-book.html). 
- **Lectures facultatif**: [Demo of the TD algorithm](https://www.cs.toronto.edu/~lcharlin/courses/80-629/reinforcejs/gridworld_td.html) (de Andrej Karpathy)
- **Sommaire**: [Lien](colab.research.google.com/drive/1nwsuHsv2f_Ac151dtOegoTiXRk65Cjr0#scrollTo=Z_LTBtfMBvW_&uniqifier=1)
- **Exercice**: [Exercices](https://colab.research.google.com/github/lcharlin/80-629/blob/master/week13-RL/Monte_Carlo_Questions-fr.ipynb), [Solution](https://colab.research.google.com/github/lcharlin/80-629/blob/master/week13-RL/Monte_Carlo_Solution-fr.ipynb)

___
14- <span style="font-size:1em;">Présentations des projets(le 29 Novembre): **Poster**</span>
* Local: à communiquer




[def]: https://www.deeplearningbook.org/contents/prob.htmlS